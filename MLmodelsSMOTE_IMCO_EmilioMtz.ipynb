{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #: Importing pandas library for data manipulation and analysis\n",
    "import numpy as np  #: Importing numpy library for numerical operations\n",
    "from sklearn import model_selection  #: Importing model_selection module from scikit-learn for model selection\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score  #: Importing evaluation metrics from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier  #: Importing RandomForestClassifier from scikit-learn for random forest algorithm\n",
    "from sklearn.model_selection import RandomizedSearchCV  #: Importing RandomizedSearchCV for hyperparameter tuning\n",
    "from sklearn.preprocessing import StandardScaler  #: Importing StandardScaler for data scaling\n",
    "import matplotlib.pyplot as plt  #: Importing matplotlib.pyplot for data visualization\n",
    "import seaborn as sns  #: Importing seaborn for advanced visualization\n",
    "from scipy import stats  #: Importing stats module from scipy for statistical operations\n",
    "from scipy.stats import randint  #: Importing randint for generating random integers\n",
    "from sklearn.ensemble import ExtraTreesClassifier  #: Importing ExtraTreesClassifier from scikit-learn for extra trees algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier  #: Importing AdaBoostClassifier from scikit-learn for AdaBoost algorithm\n",
    "from sklearn import svm  #: Importing svm module from scikit-learn for support vector machines\n",
    "from sklearn.svm import SVC  #: Importing SVC for support vector classification\n",
    "from sklearn.neural_network import MLPClassifier  #: Importing MLPClassifier from scikit-learn for multi-layer perceptron algorithm\n",
    "from sklearn.naive_bayes import GaussianNB  #: Importing GaussianNB from scikit-learn for Naive Bayes algorithm\n",
    "from sklearn.model_selection import train_test_split  #: Importing train_test_split for splitting the dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier  #: Importing KNeighborsClassifier from scikit-learn for k-nearest neighbors algorithm\n",
    "from imblearn import under_sampling, over_sampling  #: Importing under_sampling and over_sampling modules from imblearn for handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE  #: Importing SMOTE for oversampling the minority class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data\n",
    "DataIMCO_N = pd.read_csv(\"IMCO_N.csv\", low_memory=False)  #: Loading data from \"IMCO_N.csv\" into a pandas DataFrame\n",
    "DataIMCO_PR = pd.read_csv(\"IMCO_PreRed.csv\", low_memory=False)  #: Loading data from \"IMCO_PreRed.csv\" into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667316, 47)\n",
      "(667316, 61)\n"
     ]
    }
   ],
   "source": [
    "# Downloading the data\n",
    "DataIMCO_N = pd.read_csv(\"IMCO_N.csv\", low_memory=False)  #: Loading data from \"IMCO_N.csv\" into a pandas DataFrame\n",
    "DataIMCO_PR = pd.read_csv(\"IMCO_PreRed.csv\", low_memory=False)  #: Loading data from \"IMCO_PreRed.csv\" into a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column 'Unnamed: 0' from DataIMCO_N\n",
    "DataIMCO_N = DataIMCO_N.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Remove the column 'Unnamed: 0' from DataIMCO_PR\n",
    "DataIMCO_PR = DataIMCO_PR.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the non-profit dataset\n",
    "# Drop the 'Status' column from DataIMCO_N to create the feature matrix X_n\n",
    "X_n = DataIMCO_N.drop('Status', axis=1)\n",
    "\n",
    "# Extract the 'Status' column from DataIMCO_N as the target variable y_n\n",
    "y_n = DataIMCO_N['Status']\n",
    "\n",
    "# Split the non-profit dataset into training and testing sets\n",
    "X_trainn, X_testn, y_trainn, y_testn = train_test_split(X_n, y_n, test_size=0.3)\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique) to balance the non-profit dataset\n",
    "smote = SMOTE(random_state=17)\n",
    "X_trainn, y_trainn = smote.fit_resample(X_trainn, y_trainn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the for-profit dataset\n",
    "# Drop the 'Status' column from DataIMCO_PR to create the feature matrix X_r\n",
    "X_r = DataIMCO_PR.drop('Status', axis=1)\n",
    "\n",
    "# Extract the 'Status' column from DataIMCO_PR as the target variable y_r\n",
    "y_r = DataIMCO_PR['Status']\n",
    "\n",
    "# Split the for-profit dataset into training and testing sets\n",
    "X_trainp, X_testp, y_trainp, y_testp = train_test_split(X_r, y_r, test_size=0.3)\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique) to balance the for-profit dataset\n",
    "smote = SMOTE(random_state=17)\n",
    "X_trainp, y_trainp = smote.fit_resample(X_trainp, y_trainp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape and distribution of target variables\n",
    "print(DataRPS_N.shape) # Print the shape of DataRPS_N dataframe\n",
    "print(DataRPS_RedFlags.shape) # Print the shape of DataRPS_RedFlags dataframe\n",
    "print(y_trainp.shape) # Print the shape of y_trainp\n",
    "print(y_testp.shape) # Print the shape of y_testp\n",
    "print(y_trainn.shape) # Print the shape of y_trainn\n",
    "print(y_testn.shape) # Print the shape of y_testn\n",
    "print(y_trainn.value_counts()) # Print the value counts of y_trainn\n",
    "print(y_testn.value_counts()) # Print the value counts of y_testn\n",
    "print(y_trainp.value_counts()) # Print the value counts of y_trainp\n",
    "print(y_testp.value_counts()) # Print the value counts of y_testp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199882\n",
      "           1       0.13      0.09      0.11       313\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       0.56      0.54      0.55    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199691    191]\n",
      " [   285     28]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.5442506526134765\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the Random Forest classifier\n",
    "params = {\n",
    "    'n_estimators': 4000,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 80,\n",
    "    'bootstrap': False\n",
    "}\n",
    "\n",
    "# Create an instance of the Random Forest classifier with the specified parameters\n",
    "IMCO_rf_norm = RandomForestClassifier(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    min_samples_split=params['min_samples_split'],\n",
    "    min_samples_leaf=params['min_samples_leaf'],\n",
    "    max_features=params['max_features'],\n",
    "    max_depth=params['max_depth'],\n",
    "    bootstrap=params['bootstrap']\n",
    ")\n",
    "\n",
    "# Fit the Random Forest classifier to the training data\n",
    "IMCO_rf_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Make predictions on the test data using the trained classifier\n",
    "IMCOy_pred_rand_norm = IMCO_rf_norm.predict(X_testn)\n",
    "\n",
    "# Print the results\n",
    "print('RANDOM FOREST NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_testn, IMCOy_pred_rand_norm))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCOy_pred_rand_norm))\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Calculate and print the ROC AUC score\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCOy_pred_rand_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances using the trained Random Forest classifier\n",
    "feat_importances_norm = pd.Series(IMCO_rf_norm.feature_importances_, index=X_trainn.columns)\n",
    "\n",
    "# Select the top 10 most important features and plot them in a horizontal bar chart\n",
    "feat_importances_norm.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST RED FLAG DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199877\n",
      "           1       1.00      0.70      0.82       318\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       1.00      0.85      0.91    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199877      0]\n",
      " [    96    222]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.8490566037735849\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest classifier with specified hyperparameters\n",
    "# {'n_estimators': 2500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}\n",
    "IMCO_rf_red = RandomForestClassifier(n_estimators=4000,\n",
    "                                     min_samples_split=5,\n",
    "                                     min_samples_leaf=2,\n",
    "                                     max_features='sqrt',\n",
    "                                     max_depth=50,\n",
    "                                     bootstrap=False)\n",
    "\n",
    "# Train the Random Forest classifier using the training data\n",
    "IMCO_rf_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained classifier\n",
    "IMCOy_pred_rand_red = IMCO_rf_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the Random Forest classifier on the red flag data\n",
    "print('RANDOM FOREST RED FLAG DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Print the classification report, including precision, recall, F1-score, and support\n",
    "print(classification_report(y_testp, IMCOy_pred_rand_red))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCOy_pred_rand_red))\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Print the ROC AUC score\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCOy_pred_rand_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances using the trained Random Forest classifier for red flag data\n",
    "feat_importances_red = pd.Series(IMCO_rf_red.feature_importances_, index=X_trainp.columns)\n",
    "\n",
    "# Select the top 10 most important features\n",
    "top_10_features_red = feat_importances_red.nlargest(10)\n",
    "\n",
    "# Plot the top 10 features in a horizontal bar plot\n",
    "top_10_features_red.plot(kind='barh')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOSTCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\permi\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\permi\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\permi\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST CLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199882\n",
      "           1       0.11      0.05      0.07       313\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       0.55      0.52      0.53    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199762    120]\n",
      " [   298     15]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.5236614842373615\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost classifier with specified hyperparameters for normal data\n",
    "IMCO_XGBC_norm = XGBClassifier(subsample=0.9,\n",
    "                               n_estimators=300,\n",
    "                               max_depth=11,\n",
    "                               learning_rate=0.1)\n",
    "\n",
    "# Fit the XGBoost classifier on the training data\n",
    "IMCO_XGBC_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Make predictions on the test data using the trained XGBoost classifier\n",
    "IMCO_pred_xgbc_norm = IMCO_XGBC_norm.predict(X_testn)\n",
    "\n",
    "# Print the performance metrics for the XGBoost classifier on the test data\n",
    "print('XGBOOST CLASSIFIER NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testn, IMCO_pred_xgbc_norm))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_xgbc_norm))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_xgbc_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST CLASSIFIER PREPROCESSED & RED DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199877\n",
      "           1       1.00      0.86      0.92       318\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       1.00      0.93      0.96    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199876      1]\n",
      " [    44    274]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.9308151085244469\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost classifier with specified hyperparameters for preprocessed and red data\n",
    "IMCO_XGBC_red = XGBClassifier(subsample=0.8,\n",
    "                              n_estimators=300,\n",
    "                              max_depth=11,\n",
    "                              learning_rate=0.1)\n",
    "\n",
    "# Fit the XGBoost classifier on the preprocessed and red data\n",
    "IMCO_XGBC_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained XGBoost classifier\n",
    "IMCO_pred_xgbc_red = IMCO_XGBC_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the XGBoost classifier on the test data\n",
    "print('XGBOOST CLASSIFIER PREPROCESSED & RED DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_xgbc_red))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_xgbc_red))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_xgbc_red))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EXTRATREESCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRATREESCLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199882\n",
      "           1       0.08      0.09      0.09       313\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       0.54      0.55      0.54    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199545    337]\n",
      " [   284     29]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.5454828812258018\n"
     ]
    }
   ],
   "source": [
    "# {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
    "IMCO_ETC_norm = ExtraTreesClassifier(n_estimators=500,\n",
    "                                     min_samples_split=2,\n",
    "                                     min_samples_leaf=1,\n",
    "                                     max_depth=None)\n",
    "\n",
    "IMCO_ETC_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "IMCO_pred_etc_norm = IMCO_ETC_norm.predict(X_testn)\n",
    "\n",
    "print('EXTRATREESCLASSIFIER NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testn, IMCO_pred_etc_norm))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_etc_norm))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_etc_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRATREESCLASSIFIER REDFLAGS DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199877\n",
      "           1       1.00      0.64      0.78       318\n",
      "\n",
      "    accuracy                           1.00    200195\n",
      "   macro avg       1.00      0.82      0.89    200195\n",
      "weighted avg       1.00      1.00      1.00    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[199877      0]\n",
      " [   116    202]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.8176100628930818\n"
     ]
    }
   ],
   "source": [
    "# Create an ExtraTreesClassifier with specified hyperparameters for red flags data\n",
    "IMCO_ETC_red = ExtraTreesClassifier(n_estimators=500,\n",
    "                                    min_samples_split=10,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    max_depth=None)\n",
    "\n",
    "# Fit the ExtraTreesClassifier on the red flags data\n",
    "IMCO_ETC_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained ExtraTreesClassifier\n",
    "IMCO_pred_etc_red = IMCO_ETC_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the ExtraTreesClassifier on the test data\n",
    "print('EXTRATREESCLASSIFIER REDFLAGS DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_etc_red))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_etc_red))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_etc_red))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTILAYER PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88    199882\n",
      "           1       0.00      0.61      0.01       313\n",
      "\n",
      "    accuracy                           0.79    200195\n",
      "   macro avg       0.50      0.70      0.44    200195\n",
      "weighted avg       1.00      0.79      0.88    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[157092  42790]\n",
      " [   122    191]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.6980736685762811\n"
     ]
    }
   ],
   "source": [
    "# Create an MLPClassifier with specified hyperparameters for normal data\n",
    "IMCO_MLP_norm = MLPClassifier(solver='adam',\n",
    "                              max_iter=300,\n",
    "                              learning_rate='adaptive',\n",
    "                              hidden_layer_sizes=(100,),\n",
    "                              alpha=0.001,\n",
    "                              activation='relu')\n",
    "\n",
    "# Fit the MLPClassifier on the normal data\n",
    "IMCO_MLP_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Make predictions on the test data using the trained MLPClassifier\n",
    "IMCO_pred_mlpc_norm = IMCO_MLP_norm.predict(X_testn)\n",
    "\n",
    "# Print the performance metrics for the MLPClassifier on the test data\n",
    "print('MLP NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testn, IMCO_pred_mlpc_norm))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_mlpc_norm))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_mlpc_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP REDFLAGS DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43    199877\n",
      "           1       0.00      0.87      0.00       318\n",
      "\n",
      "    accuracy                           0.27    200195\n",
      "   macro avg       0.50      0.57      0.22    200195\n",
      "weighted avg       1.00      0.27      0.43    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[ 54617 145260]\n",
      " [    40    278]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.5737334435520612\n"
     ]
    }
   ],
   "source": [
    "# Create an MLPClassifier with specified hyperparameters for red flags data\n",
    "IMCO_MLP_red = MLPClassifier(solver='adam',\n",
    "                             max_iter=300,\n",
    "                             learning_rate='adaptive',\n",
    "                             hidden_layer_sizes=(100, 50),\n",
    "                             alpha=0.001,\n",
    "                             activation='logistic')\n",
    "\n",
    "# Fit the MLPClassifier on the red flags data\n",
    "IMCO_MLP_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained MLPClassifier\n",
    "IMCO_pred_mlpc_red = IMCO_MLP_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the MLPClassifier on the test data\n",
    "print('MLP REDFLAGS DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_mlpc_red))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_mlpc_red))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_mlpc_red))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02    199882\n",
      "           1       0.00      0.98      0.00       313\n",
      "\n",
      "    accuracy                           0.01    200195\n",
      "   macro avg       0.50      0.50      0.01    200195\n",
      "weighted avg       1.00      0.01      0.02    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[  2398 197484]\n",
      " [     6    307]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.4964138746013502\n"
     ]
    }
   ],
   "source": [
    "# Create a GaussianNB classifier with specified hyperparameters for normal data\n",
    "IMCO_NBclass_norm = GaussianNB(var_smoothing=8.111308307896872e-05)\n",
    "\n",
    "# Fit the GaussianNB classifier on the normal data\n",
    "IMCO_NBclass_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Make predictions on the test data using the trained GaussianNB classifier\n",
    "IMCO_pred_nbclass_norm = IMCO_NBclass_norm.predict(X_testn)\n",
    "\n",
    "# Print the performance metrics for the GaussianNB classifier on the test data\n",
    "print('NAIVE BAYES CLASSIFIER NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testn, IMCO_pred_nbclass_norm))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_nbclass_norm))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_nbclass_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18    199877\n",
      "           1       0.00      0.97      0.00       318\n",
      "\n",
      "    accuracy                           0.10    200195\n",
      "   macro avg       0.50      0.54      0.09    200195\n",
      "weighted avg       1.00      0.10      0.18    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[ 20219 179658]\n",
      " [     8    310]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.537999989490392\n"
     ]
    }
   ],
   "source": [
    "# Create a GaussianNB classifier with specified hyperparameters for red flag data\n",
    "IMCO_NBclass_red = GaussianNB(var_smoothing=2.848035868435799e-08)\n",
    "\n",
    "# Fit the GaussianNB classifier on the red flag data\n",
    "IMCO_NBclass_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained GaussianNB classifier\n",
    "IMCO_pred_nbclass_red = IMCO_NBclass_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the GaussianNB classifier on the test data\n",
    "print('NAIVE BAYES CLASSIFIER NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_nbclass_red))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_nbclass_red))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_nbclass_red))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEAREST NEIGHBOR CLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91    199882\n",
      "           1       0.00      0.34      0.01       313\n",
      "\n",
      "    accuracy                           0.83    200195\n",
      "   macro avg       0.50      0.59      0.46    200195\n",
      "weighted avg       1.00      0.83      0.91    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[166706  33176]\n",
      " [   206    107]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.5879375540834268\n"
     ]
    }
   ],
   "source": [
    "# Create a KNeighborsClassifier with specified hyperparameters for normal data\n",
    "IMCO_knc_norm = KNeighborsClassifier(weights='uniform',\n",
    "                                n_neighbors=1,\n",
    "                                metric='euclidean')\n",
    "\n",
    "# Fit the KNeighborsClassifier on the normal data\n",
    "IMCO_knc_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Make predictions on the test data using the trained KNeighborsClassifier\n",
    "IMCO_pred_knc_norm = IMCO_knc_norm.predict(X_testn)\n",
    "\n",
    "# Print the performance metrics for the KNeighborsClassifier on the test data\n",
    "print('NEAREST NEIGHBOR CLASSIFIER NORMAL DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testn, IMCO_pred_knc_norm))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_knc_norm))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_knc_norm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEAREST NEIGHBOR CLASSIFIER NORMAL DATA\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    199877\n",
      "           1       0.15      0.81      0.25       318\n",
      "\n",
      "    accuracy                           0.99    200195\n",
      "   macro avg       0.57      0.90      0.62    200195\n",
      "weighted avg       1.00      0.99      0.99    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[198416   1461]\n",
      " [    61    257]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.9004333026446486\n"
     ]
    }
   ],
   "source": [
    "# Create a KNeighborsClassifier with specified hyperparameters for red flags data\n",
    "IMCO_knc_red = KNeighborsClassifier(weights='uniform',\n",
    "                                n_neighbors=1,\n",
    "                                metric='euclidean')\n",
    "\n",
    "# Fit the KNeighborsClassifier on the red flags data\n",
    "IMCO_knc_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "# Make predictions on the test data using the trained KNeighborsClassifier\n",
    "IMCO_pred_knc_red = IMCO_knc_red.predict(X_testp)\n",
    "\n",
    "# Print the performance metrics for the KNeighborsClassifier on the test data\n",
    "print('NEAREST NEIGHBOR CLASSIFIER RED FLAGS DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_knc_red))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_knc_red))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_knc_red))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\permi\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\permi\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\permi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    198255\n",
      "           1       0.24      0.04      0.07      1940\n",
      "\n",
      "    accuracy                           0.99    200195\n",
      "   macro avg       0.62      0.52      0.53    200195\n",
      "weighted avg       0.98      0.99      0.99    200195\n",
      "\n",
      "MLPC RED FLAGS DATA\n",
      "{'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 500, 'C': 100}\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    199846\n",
      "           1       0.04      0.24      0.07       349\n",
      "\n",
      "    accuracy                           0.99    200195\n",
      "   macro avg       0.52      0.62      0.53    200195\n",
      "weighted avg       1.00      0.99      0.99    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[197991   1855]\n",
      " [   264     85]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.6171354306713017\n"
     ]
    }
   ],
   "source": [
    "# {'solver': 'newton-cg', 'penalty': 'l2', 'max_iter': 500, 'C': 100}\n",
    "\n",
    "IMCO_LR_norm = LogisticRegression(solver='newton-cg',\n",
    "                        penalty='l2',\n",
    "                        max_iter=500,\n",
    "                        C=100)\n",
    "\n",
    "# Fit the LogisticRegression on the normal data\n",
    "IMCO_LR_norm.fit(X_trainn, y_trainn)\n",
    "\n",
    "# Predict the target variable for the test data using the trained model\n",
    "IMCO_pred_lr_norm = IMCO_LR_norm.predict(X_testn)\n",
    "\n",
    "# Print the performance metrics for the LogisticRegression on the normal data\n",
    "print('MLPC RED FLAGS DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_testn, IMCO_pred_lr_norm))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testn, IMCO_pred_lr_norm))\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Print the ROC AUC score\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testn, IMCO_pred_lr_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98    190945\n",
      "           1       0.50      0.02      0.04      9250\n",
      "\n",
      "    accuracy                           0.95    200195\n",
      "   macro avg       0.73      0.51      0.51    200195\n",
      "weighted avg       0.93      0.95      0.93    200195\n",
      "\n",
      "MLPC RED FLAGS DATA\n",
      "{'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 500, 'C': 10}\n",
      "TEST PERFORMANCE\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98    199833\n",
      "           1       0.02      0.50      0.04       362\n",
      "\n",
      "    accuracy                           0.95    200195\n",
      "   macro avg       0.51      0.73      0.51    200195\n",
      "weighted avg       1.00      0.95      0.97    200195\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[190765   9068]\n",
      " [   180    182]]\n",
      "------------------------------------------------------------\n",
      "ROC_AUC_SCORE\n",
      "------------------------------------------------------------\n",
      "0.7286922702003135\n"
     ]
    }
   ],
   "source": [
    "# {'solver': 'liblinear', 'penalty': 'l1', 'max_iter': 500, 'C': 10}\n",
    "\n",
    "IMCO_LR_red = LogisticRegression(solver='liblinear',\n",
    "                        penalty='l1',\n",
    "                        max_iter=500,\n",
    "                        C=10)\n",
    "\n",
    "IMCO_LR_red.fit(X_trainp, y_trainp)\n",
    "\n",
    "IMCO_pred_rand_rf = IMCO_LR_red.predict(X_testp)\n",
    "\n",
    "\n",
    "print('MLPC RED FLAGS DATA')\n",
    "print('TEST PERFORMANCE')\n",
    "print('------------------------------------------------------------')\n",
    "print(classification_report(y_testp, IMCO_pred_rand_rf))\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_testp, IMCO_pred_rand_rf))\n",
    "print('------------------------------------------------------------')\n",
    "print('ROC_AUC_SCORE')\n",
    "print('------------------------------------------------------------')\n",
    "print(roc_auc_score(y_testp, IMCO_pred_rand_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
