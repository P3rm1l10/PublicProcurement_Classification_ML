{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script starts by importing the required packages, including pandas, numpy, datetime, and matplotlib.pyplot.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script loads the \"Contratos_IRC_2018-2021.csv\" file into a pandas DataFrame named \"data_IRC\".\n",
    "data_IRC = pd.read_csv(\"Contratos_IRC_2018-2021.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msno.matrix(data_IRC)\n",
    "#plt.figure(figsize = (15,15))\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several columns are dropped from the \"data_IRC\" DataFrame using the drop() function. These columns have more than 70% missing data or do not provide relevant information.\n",
    "data_IRC.drop(['Participantes',\n",
    "           'Ausencia.Competencia',\n",
    "           'Diferencia.creación.contrato',\n",
    "           'Reciente.creación',\n",
    "           'exclusivo_mipymes_no_respetado',\n",
    "           'Fecha.de.fallo',\n",
    "           'Plazos.Cortos',\n",
    "           'Rebasa.monto',\n",
    "           'IR.sin.documento',\n",
    "           'LP.sin.documento',\n",
    "           'Nombre.de.la.UC',\n",
    "           'Número.del.procedimiento',\n",
    "           'Código.del.contrato',\n",
    "           'Título.del.contrato',\n",
    "           'Descripción.del.contrato',\n",
    "           'Dirección.del.anuncio',\n",
    "           'Contrato.marco',\n",
    "           'Fecha.de.publicación',\n",
    "           'Fecha.de.apertura'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several columns are dropped from the \"data_IRC\" DataFrame using the drop() function. These columns have more than 70% missing data or do not provide relevant information.\n",
    "data_IRC.dropna(subset=['Fecha.de.inicio.del.contrato'], inplace=True)\n",
    "data_IRC.dropna(subset=['Fecha.de.fin.del.contrato'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The script renames selected columns in the \"data_IRC\" DataFrame using a dictionary called \"new_column_names\".\n",
    "new_column_names = {'Siglas.de.la.Institución': 'DepID',\n",
    "                     'Proveedor.o.contratista': 'ProvContID',\n",
    "                       'Año' : 'Year',\n",
    "                         'Importe.pesos':'Spending'}\n",
    "data_IRC = data_IRC.rename(columns=new_column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows in the \"data_IRC\" DataFrame are removed using the drop_duplicates() function.\n",
    "data_IRC.drop_duplicates(inplace=True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several columns in the \"data_IRC\" DataFrame are mapped to new values using the map() function. The mapping dictionaries are defined as \"value_mapping1\", \"value_mapping2\", \"value_mapping3\", and \"value_mapping4\".\n",
    "value_mapping1 = {'Adquisiciones': 'ADQ',\n",
    "                   'Servicios': 'S',\n",
    "                     'Obra Pública': 'OP',\n",
    "                       'Servicios Relacionados con la OP': 'SLAOP',\n",
    "                         'Arrendamientos': 'AR'}\n",
    "# Change the names of values using the map() function\n",
    "data_IRC['Tipo.de.contratación'] = data_IRC['Tipo.de.contratación'].map(value_mapping1)\n",
    "\n",
    "value_mapping2 = {'ADJUDICACIÓN DIRECTA': 'AD',\n",
    "                   'LICITACIÓN PÚBLICA': 'LP',\n",
    "                     'INVITACIÓN A CUANDO MENOS 3 PERSONAS': 'I3P',\n",
    "                       'OTRAS CONTRATACIONES': 'OTHER',\n",
    "                         'CONTRATO ENTRE ENTES PUBLICOS': 'CEEP',\n",
    "                         'PROYECTO DE CONVOCATORIA': 'PC'}\n",
    "# Change the names of values using the map() function\n",
    "data_IRC['Tipo.de.procedimiento'] = data_IRC['Tipo.de.procedimiento'].map(value_mapping2)\n",
    "\n",
    "value_mapping3 = {'Electrónica': 'ELE',\n",
    "                   'Presencial': 'PRE',\n",
    "                     'Mixta': 'MIX'}\n",
    "# Change the names of values using the map() function\n",
    "data_IRC['Forma.de.participación'] = data_IRC['Forma.de.participación'].map(value_mapping3)\n",
    "\n",
    "value_mapping4 = {'Micro': 'MIC',\n",
    "                   'Pequeña': 'PEQ',\n",
    "                     'No MIPYME': 'NOMIPYME',\n",
    "                     'Mediana': 'MED'}\n",
    "# Change the names of values using the map() function\n",
    "data_IRC['Estratificación.de.la.empresa'] = data_IRC['Estratificación.de.la.empresa'].map(value_mapping4)\n",
    "\n",
    "value_mapping5 = {'Nacional': 'N',\n",
    "                   'Internacional bajo TLC': 'ITLC',\n",
    "                     'Internacional': 'I',\n",
    "                     'Otro': 'OTHER'}\n",
    "# Change the names of values using the map() function\n",
    "data_IRC['Carácter.del.procedimiento'] = data_IRC['Carácter.del.procedimiento'].map(value_mapping5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new column named \"Status\" is added to the \"data_IRC\" DataFrame using the apply() function. The column is populated based on the values of the \"RFC.69bis\" and \"Proveedor_Sancionado\" columns.\n",
    "data_IRC['Status'] = data_IRC.apply(lambda row: 1 if row['RFC.69bis'] == 1 or row['Proveedor_Sancionado'] == 1 else 0, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating copies of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two copies of the \"data_IRC\" DataFrame named \"data_prepro\" and \"data_redf\" are created.\n",
    "data_prepro = data_IRC.copy()\n",
    "data_redf = data_IRC.copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data_prepro\" DataFrame undergoes several pre-processing steps, including converting categorical columns into dummy columns using the get_dummies() function, replacing a specific value in a column using the replace() function, and replacing missing values with the number 2.\n",
    "data_prepro = pd.get_dummies(data=data_prepro, columns=['Carácter.del.procedimiento',\n",
    "                                          'Tipo.de.contratación',\n",
    "                                          'Tipo.de.procedimiento',\n",
    "                                          'Forma.de.participación',\n",
    "                                          'Estratificación.de.la.empresa',\n",
    "                                          'Year'], prefix= ['PC',\n",
    "                                                            'CT',\n",
    "                                                            'PT',\n",
    "                                                            'PF',\n",
    "                                                            'S',\n",
    "                                                            'Year'])\n",
    "\n",
    "\n",
    "#We replace the name of a value of specific column\n",
    "cleanup_CONT_TYPE = {'Tipo.de.contratación' :{'ADQUISICIONES':'Adquisiciones'}}\n",
    "data_prepro = data_prepro.replace(cleanup_CONT_TYPE)\n",
    "\n",
    "#Replacing Missing Values with the number 2\n",
    "data_prepro[\"Sin.justificación\"] = data_prepro[\"Sin.justificación\"].fillna('2')\n",
    "data_prepro[\"AD.sin.contrato\"] = data_prepro[\"AD.sin.contrato\"].fillna('2')\n",
    "data_prepro[\"Publicación.Tardía\"] = data_prepro[\"Publicación.Tardía\"].fillna('2')\n",
    "\n",
    "\n",
    "#W\n",
    "data_prepro['Fundamento.legal'] = np.where(data_prepro['Fundamento.legal'].isna(), 0, 1)\n",
    "data_prepro['Folio.en.el.RUPC'] = np.where(data_prepro['Folio.en.el.RUPC'].isna(), 0, 1)\n",
    "data_prepro['RFC'] = np.where(data_prepro['RFC'].isna(), 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data_prepro\" DataFrame is filtered to include only selected features by indexing the DataFrame with a list of feature names.\n",
    "features = ['Fundamento.legal', 'Compra.consolidada', 'Folio.en.el.RUPC',\n",
    "       'RFC', 'RFC.verificado.en.el.SAT', 'Información_Scrapper',\n",
    "       'exclusivo_mipymes', 'testigo_social', 'archivo_fallo',\n",
    "       'archivo_apertura', 'archivo_junta', 'archivo_convocatoria',\n",
    "       'archivo_contrato', 'Spending', 'Publicación.EDCA', 'Sin.justificación',\n",
    "       'Publicación.Tardía', \n",
    "       'AD.sin.contrato', 'Link.funcional', 'Status', 'PC_I', 'PC_ITLC',\n",
    "       'PC_N', 'PC_OTHER', 'CT_ADQ', 'CT_AR', 'CT_OP', 'CT_S', 'CT_SLAOP',\n",
    "       'PT_AD', 'PT_CEEP', 'PT_I3P', 'PT_LP', 'PT_OTHER', 'PT_PC', 'PF_ELE',\n",
    "       'PF_MIX', 'PF_PRE', 'S_MED', 'S_MIC', 'S_NOMIPYME', 'S_PEQ',\n",
    "       'Year_2018.0', 'Year_2019.0', 'Year_2020.0', 'Year_2021.0']\n",
    "\n",
    "data_prepro = data_prepro[features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns 'Fecha.de.inicio.del.contrato' and 'Fecha.de.fin.del.contrato' in the 'data_redf' DataFrame are converted to datetime format using the pd.to_datetime() function. The specified format is '%d/%m/%Y'.\n",
    "data_redf['Fecha.de.inicio.del.contrato'] = pd.to_datetime(data_redf['Fecha.de.inicio.del.contrato'], format='%d/%m/%Y')\n",
    "# The 'BeginningWeek' column is created by extracting the ISO calendar week from the 'Fecha.de.inicio.del.contrato' column using the dt.isocalendar().week attribute.\n",
    "data_redf['BeginningWeek'] = data_redf['Fecha.de.inicio.del.contrato'].dt.isocalendar().week\n",
    "data_redf['Fecha.de.fin.del.contrato'] = pd.to_datetime(data_redf['Fecha.de.fin.del.contrato'], format='%d/%m/%Y')\n",
    "\n",
    "# The number of weeks the contract lasted is calculated by subtracting the 'Fecha.de.inicio.del.contrato' from the 'Fecha.de.fin.del.contrato' columns. The result is divided by 7 to convert it from days to weeks and stored in the 'EBWeeks' column.\n",
    "data_redf['EBWeeks'] = (data_redf['Fecha.de.fin.del.contrato'] - data_redf['Fecha.de.inicio.del.contrato']).dt.days // 7\n",
    "# Zero values in the 'EBWeeks' column are replaced with 1 using the replace() function.\n",
    "data_redf['EBWeeks'] = data_redf['EBWeeks'].replace(0,1)\n",
    "\n",
    "# Fraction of single bidder contracts - RAD\n",
    "#T.AD\n",
    "# A DataFrame named 'totnum_cont_bytype' is created by grouping the 'data_redf' DataFrame by 'ProvContID' and 'Tipo.de.procedimiento' columns and counting the occurrences of each type.\n",
    "totnum_cont_bytype = data_redf.groupby('ProvContID')['Tipo.de.procedimiento'].value_counts().unstack(fill_value=0)\n",
    "# The 'totnum_AD' DataFrame is created by selecting only the 'AD' column from 'totnum_cont_bytype'.\n",
    "totnum_AD = pd.DataFrame(totnum_cont_bytype['AD'])\n",
    "totnum_AD.reset_index(inplace=True)\n",
    "totnum_AD.rename(columns={'AD':'T.AD'}, inplace=True)\n",
    "\n",
    "#T.Cont\n",
    "# The 'totnum_AD' DataFrame is then merged with another DataFrame 'totnum_cont_perDep' created by counting the number of contracts per 'ProvContID'.\n",
    "totnum_cont_perDep = pd.DataFrame(data_redf['ProvContID'].value_counts())\n",
    "totnum_cont_perDep.reset_index(inplace=True)\n",
    "totnum_cont_perDep.rename(columns={\"count\":\"T.Cont\"}, inplace=True)\n",
    "totnum_AD = totnum_AD.merge(totnum_cont_perDep, how='left', on='ProvContID')\n",
    "# The 'RAD' column is created by dividing the 'T.AD' column by the 'T.Cont' column.\n",
    "totnum_AD['RAD'] = totnum_AD['T.AD']/totnum_AD['T.Cont']\n",
    "# The 'data_redf' DataFrame is merged with the 'totnum_AD' DataFrame based on 'ProvContID' and 'data_redf' is updated with the merged results.\n",
    "data_redf = pd.merge(data_redf,totnum_AD, how='left', on=['ProvContID'])\n",
    "\n",
    "\n",
    "#Exist or does not exist in RUPC\n",
    "# Duplicate rows with unique combinations of 'Folio.en.el.RUPC' and 'ProvContID' are extracted into the 'unique_values' DataFrame.\n",
    "unique_values = data_redf.drop_duplicates(subset=['Folio.en.el.RUPC', 'ProvContID'])\n",
    "unique_values = unique_values[[\"Folio.en.el.RUPC\", \"ProvContID\"]]\n",
    "# The 'unique_values' DataFrame is merged with the 'data_redf' DataFrame based on 'ProvContID' and 'Folio.en.el.RUPC'.\n",
    "data_redf = data_redf.merge(unique_values, how='left', on=['ProvContID','Folio.en.el.RUPC'])\n",
    "# The 'RUPC' column is created in the 'data_redf' DataFrame, where if 'Folio.en.el.RUPC' is null, the value is set to 0; otherwise, it is set to 1.\n",
    "data_redf['RUPC'] = np.where(data_redf['Folio.en.el.RUPC'].isnull(), 0, 1)\n",
    "\n",
    "# Calculate the maximum number of contracts by a buyer (T.Cont.Max)\n",
    "#Maximum number of Contracts by a buyer (Maximum number of the contracts awarded by a buyer to a supplier maxj (T.Contj ) where j represents all the suppliers contracted by a buyer,and T.Cont th)\n",
    "# The 'df_counts' DataFrame is created by grouping the 'data_redf' DataFrame by 'Institución' and 'ProvContID' and counting the occurrences of each combination.\n",
    "df_counts = data_redf.groupby(['Institución', 'ProvContID']).size().reset_index(name='num_contracts')\n",
    "# The 'max_counts' DataFrame is created by grouping the 'df_counts' DataFrame by 'ProvContID' and selecting the maximum value of 'num_contracts'.\n",
    "max_counts = pd.DataFrame(df_counts.groupby('ProvContID')['num_contracts'].max().reset_index(name='T.Cont.Max'))\n",
    "# The 'data_redf' DataFrame is merged with the 'max_counts' DataFrame based on 'ProvContID', and 'data_redf' is updated with the merged results.\n",
    "data_redf = data_redf.merge(max_counts, how='left', on='ProvContID')\n",
    "\n",
    "#T.Spending.Max\n",
    "#Maximum Spending by a buyer (Maximum amount of money spent by a buyer in contracts with a supplier maxj (T.Spendingj ) where j represents all the suppliers contracted by the buyer, and T_Spending the amount of money given to each supplier)\n",
    "# The 'max_amount' DataFrame is created by grouping the 'data_redf' DataFrame by 'Institución' and 'ProvContID' and selecting the maximum value of the 'Spending' column.\n",
    "max_amount = data_redf.groupby(['Institución','ProvContID'])['Spending'].max().reset_index(name='T.Spending.Max')\n",
    "# The 'data_redf' DataFrame is merged with the 'max_amount' DataFrame based on 'Institución' and 'ProvContID', and 'data_redf' is updated with the merged results.\n",
    "data_redf = data_redf.merge(max_amount, how='left', on=['Institución','ProvContID'])\n",
    "\n",
    "#Spending by buyer(Amount of money given to each supplier) \n",
    "# The 'Spend_by_buyer' DataFrame is created by grouping the 'data_redf' DataFrame by 'ProvContID' and summing the values in the 'Spending' column.\n",
    "Spend_by_buyer = pd.DataFrame(data_redf.groupby('ProvContID')['Spending'].sum())\n",
    "# The 'Spending' column in 'Spend_by_buyer' is renamed to 'T.Spending'.\n",
    "Spend_by_buyer.rename(columns={\"Spending\":\"T.Spending\"}, inplace=True)\n",
    "# The 'data_redf' DataFrame is merged with the 'Spend_by_buyer' DataFrame based on 'ProvContID', and 'data_redf' is updated with the merged results.\n",
    "data_redf = data_redf.merge(Spend_by_buyer, how='left', on='ProvContID')\n",
    "\n",
    "#Active Weeks\n",
    "# The 'Active_Weeks' DataFrame is created by grouping the 'data_redf' DataFrame by 'ProvContID', 'DepID', and 'Year', and summing the values in the 'EBWeeks' column.\n",
    "Active_Weeks = data_redf.groupby([\"ProvContID\",'DepID','Year'])['EBWeeks'].sum().reset_index(name='ActiveWeeks')\n",
    "# The 'data_redf' DataFrame is merged with the 'Active_Weeks' DataFrame based on 'ProvContID', 'DepID', and 'Year', and 'data_redf' is updated with the merged results.\n",
    "data_redf = pd.merge(data_redf, Active_Weeks, on=['ProvContID','DepID','Year'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The \"data_redf\" DataFrame undergoes dummy encoding for selected categorical columns using the get_dummies() function.\n",
    "data_redf = pd.get_dummies(data=data_redf, columns=['Carácter.del.procedimiento',\n",
    "                                          'Tipo.de.contratación',\n",
    "                                          'Tipo.de.procedimiento',\n",
    "                                          'Forma.de.participación',\n",
    "                                          'Estratificación.de.la.empresa'], prefix= ['PC',\n",
    "                                                            'CT',\n",
    "                                                            'PT',\n",
    "                                                            'PF',\n",
    "                                                            'S'])\n",
    "\n",
    "# The 'cleanup_CONT_TYPE' dictionary is defined to map the value 'ADQUISICIONES' in the 'Tipo.de.contratación' column to 'Adquisiciones'.\n",
    "cleanup_CONT_TYPE = {'Tipo.de.contratación' :{'ADQUISICIONES':'Adquisiciones'}}\n",
    "# The 'replace()' function is used to replace the values in the 'Tipo.de.contratación' column according to the 'cleanup_CONT_TYPE' dictionary.\n",
    "data_redf = data_redf.replace(cleanup_CONT_TYPE)\n",
    "\n",
    "\n",
    "# The fillna() function is used to fill missing values in specific columns of the data_redf DataFrame.\n",
    "# The missing values in these columns are filled with the value '2'.\n",
    "data_redf[\"AD.sin.contrato\"] = data_redf[\"AD.sin.contrato\"].fillna('2')\n",
    "data_redf[\"Sin.justificación\"] = data_redf[\"Sin.justificación\"].fillna('2')\n",
    "data_redf[\"Publicación.Tardía\"] = data_redf[\"Publicación.Tardía\"].fillna('2')\n",
    "\n",
    "# The 'Fundamento.legal', 'Folio.en.el.RUPC', and 'RFC' columns are updated to binary values indicating the presence or absence of missing values.\n",
    "data_redf['Fundamento.legal'] = np.where(data_redf['Fundamento.legal'].isna(), 0, 1)\n",
    "data_redf['Folio.en.el.RUPC'] = np.where(data_redf['Folio.en.el.RUPC'].isna(), 0, 1)\n",
    "data_redf['RFC'] = np.where(data_redf['RFC'].isna(), 0, 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New RedFlags\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\t\tPercentage of split contracts per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 63)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We filter the main database for non-competitive contracts, namely Direct Award and Restricted Invitation.\n",
    "data_RPS_without_PTLP = data_redf[(data_redf[\"PT_AD\"] == 1) | (data_redf[\"PT_I3P\"] == 1)]\n",
    "\n",
    "#We create a pivot table to identify the number of contracts that occurred in the same week and year.\n",
    "data_RPS_without_PTLP_sameWandY = data_RPS_without_PTLP.groupby(['ProvContID', 'DepID', 'Year', 'BeginningWeek'])['BeginningWeek'].count().reset_index(name=\"Same_BegWeekandYear_Count\")\n",
    "\n",
    "#We filter for suppliers and contractors who have had more than one contracting process in the same week of the same year.\n",
    "data_RPS_without_PTLP_sameWandY = data_RPS_without_PTLP_sameWandY[data_RPS_without_PTLP_sameWandY[\"Same_BegWeekandYear_Count\"] > 1]\n",
    "\n",
    "#We select the columns of interest.\n",
    "data_RPS_without_PTLP_sameWandY = data_RPS_without_PTLP_sameWandY[[\"ProvContID\", \"Year\", \"DepID\", \"BeginningWeek\", \"Same_BegWeekandYear_Count\"]]\n",
    "\n",
    "#This table shows the number of contracting processes by suppliers and contractors per year.\n",
    "ProvContID_tot_perY = data_redf.groupby([\"ProvContID\", \"DepID\", \"Year\"]).count().reset_index()\n",
    "\n",
    "#We remove the unwanted columns.\n",
    "ProvContID_tot_perY = ProvContID_tot_perY[['ProvContID', 'DepID', 'Year', 'Status']]\n",
    "\n",
    "#We rename the \"Status\" column to \"Tot_ProvContID_per_Year\" (Total number of contracts by Supplier and Department per Year).\n",
    "ProvContID_tot_perY = ProvContID_tot_perY.rename(columns={'Status': 'Tot_ProvContID_per_Year'})\n",
    "\n",
    "#We merge the previous table with the table of contracting processes by suppliers and contractors per year.\n",
    "merge1 = pd.merge(data_RPS_without_PTLP_sameWandY, ProvContID_tot_perY, on=['ProvContID', 'DepID', 'Year'], how='right')\n",
    "\n",
    "#We create a column that shows the percentage of contracts that were split in the same week of the same year.\n",
    "merge1['Perc_Split_Contracts'] = merge1['Same_BegWeekandYear_Count'] / merge1['Tot_ProvContID_per_Year']\n",
    "\n",
    "#We fill the null values with 0.\n",
    "merge1['Perc_Split_Contracts'].fillna(0, inplace=True)\n",
    "\n",
    "#We remove the unwanted columns.\n",
    "merge1 = merge1[['ProvContID', 'DepID', 'Year', 'Perc_Split_Contracts']]\n",
    "\n",
    "#We remove duplicates.\n",
    "merge1 = merge1.drop_duplicates(['ProvContID', 'DepID', 'Year'])\n",
    "\n",
    "#We merge the previous table with the main table.\n",
    "data_redf = pd.merge(data_redf, merge1, on=['ProvContID', 'DepID', 'Year'], how='left')\n",
    "data_redf.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "•\tPercentage of non-open procedures by government agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We filter the data that is not PT.AD (non-Direct Award).\n",
    "data_PT_AD_1 = data_redf[data_redf[\"PT_AD\"] == 1]\n",
    "\n",
    "#We group by DepID and count the number of PT.AD to determine the total number of Direct Awards per institution and year.\n",
    "data_PT_AD_1 = data_PT_AD_1.groupby(['DepID', 'Year'])['PT_AD'].count().reset_index(name='Total_AD_DepID')\n",
    "\n",
    "#This table shows the number of tenders per department and year.\n",
    "DepID_tot = data_redf.groupby(['DepID', 'Year'])['Status'].count().reset_index()\n",
    "\n",
    "#We rename the \"Status\" column to \"Tot_DepID_per_Year\" (Total number of tender processes per department and year).\n",
    "DepID_tot = DepID_tot.rename(columns={'Status': 'Tot_DepID_per_Year'})\n",
    "\n",
    "#We merge the two tables.\n",
    "DepID_AD = pd.merge(data_PT_AD_1, DepID_tot, on=['DepID', 'Year'], how='left')\n",
    "\n",
    "#We create a new column that indicates the percentage of Direct Awards per department and year.\n",
    "DepID_AD['F_NonOpen_DepID'] = DepID_AD['Total_AD_DepID'] / DepID_AD['Tot_DepID_per_Year']\n",
    "\n",
    "#We remove the unwanted columns.\n",
    "DepID_AD = DepID_AD[['DepID', 'Year', 'F_NonOpen_DepID']]\n",
    "\n",
    "#We merge the previous table with the original data table.\n",
    "data_redf = pd.merge(data_redf, DepID_AD, on=['DepID', 'Year'], how='left')\n",
    "\n",
    "#We replace the NaN values with 0.\n",
    "data_redf[\"F_NonOpen_DepID\"] = data_redf[\"F_NonOpen_DepID\"].fillna(0)\n",
    "\n",
    "data_redf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tPercentage of non-open procedures by supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 65)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We apply the same PT.AD filter and perform a similar process but with ProvContID.\n",
    "data_PT_AD_1 = data_redf[data_redf[\"PT_AD\"] == 1]\n",
    "\n",
    "# We group by ProvContID and count the number of PT.AD to determine the total number of Direct Awards per supplier and year.\n",
    "ProcContID_PT_AD_Tot = data_PT_AD_1.groupby(['ProvContID', 'Year'])['PT_AD'].count().reset_index(name='Total_AD_ProvContID')\n",
    "\n",
    "# This table shows the number of tenders per supplier and year.\n",
    "# We group by ProvContID and Year.\n",
    "ProvContID_tot = data_redf.groupby(['ProvContID', 'Year']).count().reset_index()\n",
    "\n",
    "# We remove the unwanted columns.\n",
    "ProvContID_tot = ProvContID_tot[['ProvContID', 'Year', 'Status']]\n",
    "\n",
    "# We rename the \"Status\" column to \"Num_ProvContID_per_Year\" (Total number of tender processes per supplier and year).\n",
    "ProvContID_tot = ProvContID_tot.rename(columns={'Status': 'Num_ProvContID_per_Year'})\n",
    "\n",
    "# We merge the two tables.\n",
    "data = pd.merge(ProcContID_PT_AD_Tot, ProvContID_tot, on=['ProvContID', 'Year'], how='left')\n",
    "\n",
    "# We create a new column that indicates the percentage of Direct Awards per supplier and year.\n",
    "data[\"F_NonOpen_ProvCont\"] = data[\"Total_AD_ProvContID\"] / data[\"Num_ProvContID_per_Year\"]\n",
    "\n",
    "# We remove the unwanted columns.\n",
    "data = data[['ProvContID', 'Year', 'F_NonOpen_ProvCont']]\n",
    "\n",
    "# We merge the previous table with the original data table.\n",
    "data_redf = pd.merge(data_redf, data, on=['ProvContID', 'Year'], how='left')\n",
    "\n",
    "data_redf[\"F_NonOpen_ProvCont\"] = data_redf[\"F_NonOpen_ProvCont\"].fillna(0)\n",
    "\n",
    "data_redf.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tFrequency of contracts won: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 66)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a pivot table to determine the number of contracts per department and year.\n",
    "ProvContID_perYear = data_redf.groupby(['DepID', 'Year', 'ProvContID'])['ProvContID'].count().reset_index(name='Total_ProvContID')\n",
    "\n",
    "# With this pivot table, we find the maximum number of contracts per department and year.\n",
    "Max_ProvContID_perYear = ProvContID_perYear.groupby(['DepID', 'Year'])['Total_ProvContID'].agg(max).reset_index(name='Max_Total_ProvContID')\n",
    "\n",
    "# We merge the two tables.\n",
    "data2 = pd.merge(ProvContID_perYear, Max_ProvContID_perYear, on=['DepID', 'Year'], how='left')\n",
    "\n",
    "# We create a new column that shows the standardized frequency of contracts won by company i in time t, awarded by department d.\n",
    "data2[\"F_of_Contr_Won_IMCO\"] = (data2[\"Total_ProvContID\"] * 100) / data2[\"Max_Total_ProvContID\"]\n",
    "\n",
    "# We remove the unwanted columns.\n",
    "data2 = data2[['DepID', 'Year', 'ProvContID', 'F_of_Contr_Won_IMCO']]\n",
    "\n",
    "# We merge the previous table with the original data table.\n",
    "data_redf = pd.merge(data_redf, data2, on=['DepID', 'Year', 'ProvContID'], how='left')\n",
    "\n",
    "data_redf[\"F_of_Contr_Won_IMCO\"] = data_redf[\"F_of_Contr_Won_IMCO\"].fillna(0)\n",
    "\n",
    "data_redf.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tAmount of Contracted by the supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 67)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a pivot table to determine the total spending per department, company, and year.\n",
    "Sum_Spend = data_redf.groupby(['DepID', 'Year', 'ProvContID'])['Spending'].sum().reset_index(name='Spending')\n",
    "\n",
    "# We create a pivot table to determine the maximum spending per department and year.\n",
    "Sum_Spend_max = Sum_Spend.groupby(['DepID', 'Year'])['Spending'].max().reset_index(name='Max_Spending')\n",
    "\n",
    "# We merge the two tables.\n",
    "data3 = pd.merge(Sum_Spend, Sum_Spend_max, on=['DepID', 'Year'], how='left')\n",
    "\n",
    "# We create a new column that indicates the standardized total amount of contracts for company i in year t, awarded by company d.\n",
    "data3[\"Am_Cont_by_Sup\"] = (data3[\"Spending\"] * 100) / data3[\"Max_Spending\"]\n",
    "\n",
    "# We remove the unwanted columns.\n",
    "data3 = data3[['DepID', 'Year', 'ProvContID', 'Am_Cont_by_Sup']]\n",
    "\n",
    "# We merge the previous table with the original data table.\n",
    "data_redf = pd.merge(data_redf, data3, on=['DepID', 'Year', 'ProvContID'], how='left')\n",
    "\n",
    "data_redf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•   Contracts per active weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 68)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We calculate the Contracts per Week (CPW) by dividing the total number of contracts (T.Cont) by the number of active weeks (ActiveWeeks).\n",
    "data_redf['CPW'] = data_redf['T.Cont'] / data_redf['ActiveWeeks']\n",
    "data_redf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•   Spending per active weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(667316, 69)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We calculate the Spending per Week (SPW) by dividing the total spending (T.Spending) by the number of active weeks (ActiveWeeks).\n",
    "data_redf['SPW'] = data_redf['T.Spending'] / data_redf['ActiveWeeks']\n",
    "data_redf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply one-hot encoding to the 'Year' column in the data_redf DataFrame.\n",
    "data_redf = pd.get_dummies(data_redf, columns=['Year'], prefix=['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select a subset of features from the data_redf DataFrame.\n",
    "features = ['Fundamento.legal', 'Compra.consolidada', 'Folio.en.el.RUPC', 'RFC.verificado.en.el.SAT',\n",
    "            'exclusivo_mipymes', 'testigo_social', 'archivo_fallo', 'archivo_apertura', 'archivo_junta',\n",
    "            'archivo_convocatoria', 'archivo_contrato', 'Spending', 'Publicación.EDCA', 'Sin.justificación',\n",
    "            'Publicación.Tardía', 'AD.sin.contrato', 'Link.funcional', 'Status', 'EBWeeks', 'T.AD', 'T.Cont',\n",
    "            'RAD', 'RUPC', 'T.Cont.Max', 'T.Spending.Max', 'T.Spending', 'ActiveWeeks', 'PC_I', 'PC_ITLC',\n",
    "            'PC_N', 'PC_OTHER', 'CT_ADQ', 'CT_AR', 'CT_OP', 'CT_S', 'CT_SLAOP', 'PT_AD', 'PT_CEEP', 'PT_I3P',\n",
    "            'PT_LP', 'PT_OTHER', 'PT_PC', 'PF_ELE', 'PF_MIX', 'PF_PRE', 'S_MED', 'S_MIC', 'S_NOMIPYME', 'S_PEQ',\n",
    "            'Perc_Split_Contracts', 'F_NonOpen_DepID', 'F_NonOpen_ProvCont', 'F_of_Contr_Won_IMCO', 'Am_Cont_by_Sup',\n",
    "            'CPW', 'SPW', 'Year_2018.0', 'Year_2019.0', 'Year_2020.0', 'Year_2021.0']\n",
    "\n",
    "data_redf = data_redf[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667316, 46)\n",
      "(667316, 60)\n"
     ]
    }
   ],
   "source": [
    "print(data_prepro.shape)\n",
    "print(data_redf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status\n",
      "0    666189\n",
      "1      1127\n",
      "Name: count, dtype: int64\n",
      "Status\n",
      "0    666189\n",
      "1      1127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_prepro['Status'].value_counts())\n",
    "print(data_redf['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_redf.to_csv(\"IMCO_PreRed.csv\")\n",
    "data_prepro.to_csv(\"IMCO_N.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
